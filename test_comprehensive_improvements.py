#!/usr/bin/env python3
"""
ç»¼åˆæµ‹è¯•ï¼šé˜¶æ®µ1 + é˜¶æ®µ2 å®Œæ•´é›†æˆ
éªŒè¯å»é‡ä¸­é—´ä»¶ + MemorySaver + è®°å¿†ç»„ä»¶çš„ååŒå·¥ä½œ
"""

import sys
import os
import asyncio
import time
from typing import Dict, Any, List
from dataclasses import dataclass

# æ·»åŠ  runner åˆ°è·¯å¾„
runner_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, runner_dir)


@dataclass
class TestScenario:
    """æµ‹è¯•åœºæ™¯"""

    name: str
    operations: List[Dict[str, Any]]
    expected_executed: int
    expected_skipped: int
    description: str


async def simulate_nodejs_deduplication(
    operations: List[Dict[str, Any]], time_window: int = 5000
) -> Dict[str, Any]:
    """æ¨¡æ‹Ÿ Node.js å»é‡ä¸­é—´ä»¶"""
    cache = {}
    executed = []
    skipped = []

    for i, op in enumerate(operations):
        action = op["action"]
        params = op.get("params", {})
        key = f"{action}:{str(params)}"
        now = time.time() * 1000

        if key not in cache or (now - cache[key]["timestamp"]) > time_window:
            # æ‰§è¡Œæ“ä½œ
            result = {
                "success": True,
                "action": action,
                "params": params,
                "timestamp": now,
                "index": i,
            }
            cache[key] = result
            executed.append(result)
        else:
            # è·³è¿‡æ“ä½œ
            skipped.append(
                {
                    "action": action,
                    "params": params,
                    "reason": "é‡å¤æ“ä½œ",
                    "cached_result": cache[key],
                    "index": i,
                }
            )

    return {
        "executed": executed,
        "skipped": skipped,
        "cache_size": len(cache),
        "total_operations": len(operations),
    }


async def simulate_python_memory(operations: List[Dict[str, Any]]) -> Dict[str, Any]:
    """æ¨¡æ‹Ÿ Python è®°å¿†ç»„ä»¶"""
    memory_records = []
    context_history = []

    for i, op in enumerate(operations):
        action = op["action"]
        params = op.get("params", {})
        result = op.get("result", {"success": True})

        # æ·»åŠ åˆ°è®°å¿†
        record = {
            "timestamp": time.time() + i * 0.1,
            "action": action,
            "params": params,
            "result": result,
            "context": {"url": op.get("url", "unknown"), "step": i + 1},
            "success": result.get("success", True),
        }
        memory_records.append(record)

        # æ„å»ºä¸Šä¸‹æ–‡
        if i == 0:
            context = "æ— å†å²æ“ä½œè®°å½•"
        else:
            recent = memory_records[-3:] if len(memory_records) >= 3 else memory_records
            context_lines = ["=== æœ€è¿‘æ“ä½œå†å² ==="]
            for rec in recent:
                status = "âœ…" if rec["success"] else "âŒ"
                context_lines.append(
                    f"{status} [{rec['action']}] "
                    f"å‚æ•°: {rec['params']}, "
                    f"ç»“æœ: {rec['result']}, "
                    f"é¡µé¢: {rec['context'].get('url', 'unknown')}"
                )
            context = "\n".join(context_lines)

        context_history.append(context)

    return {
        "records": memory_records,
        "contexts": context_history,
        "total_records": len(memory_records),
        "successful_records": sum(1 for r in memory_records if r["success"]),
    }


async def simulate_langgraph_memory_saver(
    operations: List[Dict[str, Any]],
) -> Dict[str, Any]:
    """æ¨¡æ‹Ÿ LangGraph MemorySaver çŠ¶æ€æŒä¹…åŒ–"""
    thread_states = {}
    message_history = []

    for i, op in enumerate(operations):
        thread_id = op.get("thread_id", "default_thread")
        action = op["action"]
        params = op.get("params", {})

        # åˆå§‹åŒ–çº¿ç¨‹çŠ¶æ€
        if thread_id not in thread_states:
            thread_states[thread_id] = {
                "message_count": 0,
                "task_count": 0,
                "last_activity": time.time(),
            }

        # æ¨¡æ‹Ÿäººç±»æ¶ˆæ¯
        human_msg = {
            "type": "human",
            "content": f"æ‰§è¡Œæ“ä½œ: {action} {params}",
            "timestamp": time.time() + i * 0.1,
        }

        # æ¨¡æ‹Ÿ AI å“åº”
        ai_msg = {
            "type": "ai",
            "content": f"å·²æ‰§è¡Œ {action}",
            "timestamp": time.time() + i * 0.1 + 0.05,
        }

        # æ›´æ–°çº¿ç¨‹çŠ¶æ€
        thread_states[thread_id]["message_count"] += 2
        thread_states[thread_id]["task_count"] += 1
        thread_states[thread_id]["last_activity"] = time.time() + i * 0.1

        message_history.append(
            {
                "thread_id": thread_id,
                "human_message": human_msg,
                "ai_message": ai_msg,
                "state": thread_states[thread_id].copy(),
            }
        )

    return {
        "thread_states": thread_states,
        "message_history": message_history,
        "total_threads": len(thread_states),
        "total_messages": sum(t["message_count"] for t in thread_states.values()),
    }


async def test_basic_usage_scenario():
    """æµ‹è¯• basic_usage.txt åœºæ™¯"""
    print("=" * 70)
    print("æµ‹è¯•åœºæ™¯: basic_usage.txt é‡å¤æ‰§è¡Œé—®é¢˜")
    print("=" * 70)

    # æ¨¡æ‹Ÿ basic_usage.txt çš„æ“ä½œåºåˆ—
    # æ¨¡æ‹Ÿ AI åœ¨é‡åˆ°å›°éš¾æ—¶åå¤å°è¯•ç›¸åŒæ“ä½œ
    operations = [
        {"action": "navigate", "params": {"url": "https://example.com"}},
        {
            "action": "find_element",
            "params": {"description": "JavaScript API å‚è€ƒèœå•é¡¹"},
        },
        {
            "action": "find_element",
            "params": {"description": "JavaScript API å‚è€ƒèœå•é¡¹"},
        },  # é‡å¤
        {
            "action": "find_element",
            "params": {"description": "JavaScript API å‚è€ƒèœå•é¡¹"},
        },  # é‡å¤
        {"action": "aiQuery", "params": {"query": "æŸ¥æ‰¾èœå•ä¸­çš„JavaScript APIå‚è€ƒ"}},
        {
            "action": "aiQuery",
            "params": {"query": "æŸ¥æ‰¾èœå•ä¸­çš„JavaScript APIå‚è€ƒ"},
        },  # é‡å¤
        {"action": "click", "params": {"element": "JavaScript API å‚è€ƒ"}},
        {"action": "find_element", "params": {"description": "API å‚è€ƒé¡µé¢"}},
        {"action": "find_element", "params": {"description": "API å‚è€ƒé¡µé¢"}},  # é‡å¤
        {"action": "screenshot", "params": {"name": "api_reference_page"}},
    ]

    print(f"\nğŸ“‹ æ¨¡æ‹Ÿæ“ä½œåºåˆ— ({len(operations)} ä¸ªæ“ä½œ):")
    for i, op in enumerate(operations, 1):
        print(f"  {i}. {op['action']} {op['params']}")

    # æµ‹è¯•å„ç»„ä»¶
    print("\nğŸ”„ æµ‹è¯•ç»„ä»¶ååŒå·¥ä½œ:")

    # 1. Node.js å»é‡ä¸­é—´ä»¶
    print("\n1ï¸âƒ£ Node.js å»é‡ä¸­é—´ä»¶:")
    dedup_result = await simulate_nodejs_deduplication(operations)
    print(f"   æ‰§è¡Œ: {len(dedup_result['executed'])} ä¸ªæ“ä½œ")
    print(f"   è·³è¿‡: {len(dedup_result['skipped'])} ä¸ªé‡å¤æ“ä½œ")
    print(f"   ç¼“å­˜: {dedup_result['cache_size']} ä¸ªå”¯ä¸€æ“ä½œ")

    # æ˜¾ç¤ºè·³è¿‡çš„æ“ä½œ
    if dedup_result["skipped"]:
        print("\n   è¢«è·³è¿‡çš„é‡å¤æ“ä½œ:")
        for skip in dedup_result["skipped"]:
            print(f"     - {skip['action']} {skip['params']} (ç´¢å¼•: {skip['index']})")

    # 2. Python è®°å¿†ç»„ä»¶
    print("\n2ï¸âƒ£ Python è®°å¿†ç»„ä»¶:")
    memory_result = await simulate_python_memory(
        [{**op, "result": {"success": True}} for op in operations]
    )
    print(f"   è®°å¿†è®°å½•: {memory_result['total_records']} æ¡")
    print(f"   æˆåŠŸè®°å½•: {memory_result['successful_records']} æ¡")

    # æ˜¾ç¤ºä¸Šä¸‹æ–‡æ„å»º
    print("\n   æ„å»ºçš„ä¸Šä¸‹æ–‡ç¤ºä¾‹:")
    if memory_result["contexts"]:
        # æ˜¾ç¤ºç¬¬4ä¸ªä¸Šä¸‹æ–‡çš„ç¤ºä¾‹ï¼ˆå·²ç»æœ‰å†å²è®°å½•æ—¶ï¼‰
        example_context = memory_result["contexts"][3]
        print(f"   {example_context[:200]}...")

    # 3. LangGraph MemorySaver
    print("\n3ï¸âƒ£ LangGraph MemorySaver:")
    saver_result = await simulate_langgraph_memory_saver(
        [{**op, "thread_id": "basic_usage_thread"} for op in operations]
    )
    print(f"   çº¿ç¨‹æ•°: {saver_result['total_threads']}")
    print(f"   æ€»æ¶ˆæ¯: {saver_result['total_messages']} æ¡")
    print(
        f"   å¹³å‡æ¯æ“ä½œ: {saver_result['total_messages'] / len(operations):.1f} æ¡æ¶ˆæ¯"
    )

    # æ˜¾ç¤ºçº¿ç¨‹çŠ¶æ€
    thread_state = list(saver_result["thread_states"].values())[0]
    print(
        f"   çº¿ç¨‹çŠ¶æ€: {thread_state['task_count']} ä¸ªä»»åŠ¡, {thread_state['message_count']} æ¡æ¶ˆæ¯"
    )

    # ç»¼åˆæ•ˆæœåˆ†æ
    print("\nğŸ“Š ç»¼åˆæ•ˆæœåˆ†æ:")
    total_skipped = len(dedup_result["skipped"])
    efficiency_improvement = (total_skipped / len(operations)) * 100

    print(f"   åŸå§‹æ“ä½œæ•°: {len(operations)}")
    print(f"   å»é‡åæ‰§è¡Œ: {len(dedup_result['executed'])}")
    print(f"   è·³è¿‡é‡å¤: {total_skipped}")
    print(f"   æ•ˆç‡æå‡: {efficiency_improvement:.1f}%")

    # çŠ¶æ€ç´¯ç§¯æ•ˆæœ
    final_message_count = saver_result["total_messages"]
    context_preserved = memory_result["total_records"] > 0

    print(
        f"   çŠ¶æ€æŒä¹…åŒ–: {'âœ…' if final_message_count > 0 else 'âŒ'} ({final_message_count} æ¡æ¶ˆæ¯)"
    )
    print(
        f"   å†å²ä¸Šä¸‹æ–‡: {'âœ…' if context_preserved else 'âŒ'} ({memory_result['total_records']} æ¡è®°å½•)"
    )

    return {
        "original_operations": len(operations),
        "executed_operations": len(dedup_result["executed"]),
        "skipped_operations": total_skipped,
        "efficiency_improvement": efficiency_improvement,
        "memory_records": memory_result["total_records"],
        "message_persistence": final_message_count,
        "success": True,
    }


async def test_multiple_threads_scenario():
    """æµ‹è¯•å¤šçº¿ç¨‹åœºæ™¯"""
    print("\n" + "=" * 70)
    print("æµ‹è¯•åœºæ™¯: å¤šçº¿ç¨‹å¹¶å‘æ‰§è¡Œ")
    print("=" * 70)

    # æ¨¡æ‹Ÿå¤šä¸ªæµ‹è¯•ç”¨ä¾‹å¹¶å‘æ‰§è¡Œ
    test_threads = {
        "basic_usage_thread": [
            {"action": "navigate", "params": {"url": "https://example.com"}},
            {"action": "click", "params": {"element": "èœå•"}},
            {"action": "find_element", "params": {"description": "API å‚è€ƒ"}},
        ],
        "github_interaction_thread": [
            {"action": "navigate", "params": {"url": "https://github.com"}},
            {"action": "click", "params": {"element": "Search"}},
            {"action": "input", "params": {"field": "search", "value": "midscene"}},
        ],
        "baidu_query_thread": [
            {"action": "navigate", "params": {"url": "https://baidu.com"}},
            {"action": "input", "params": {"field": "search", "value": "AI è‡ªåŠ¨åŒ–"}},
            {"action": "click", "params": {"element": "æœç´¢æŒ‰é’®"}},
        ],
    }

    print(f"\nğŸ§µ å¹¶å‘çº¿ç¨‹æ•°: {len(test_threads)}")

    all_results = {}

    for thread_name, operations in test_threads.items():
        print(f"\nğŸ“ {thread_name}:")
        print(f"   æ“ä½œæ•°: {len(operations)}")

        # å»é‡
        dedup_result = await simulate_nodejs_deduplication(operations)
        print(
            f"   æ‰§è¡Œ: {len(dedup_result['executed'])}, è·³è¿‡: {len(dedup_result['skipped'])}"
        )

        # è®°å¿†
        memory_result = await simulate_python_memory(
            [
                {
                    **op,
                    "result": {"success": True},
                    "url": op.get("params", {}).get("url", "unknown"),
                }
                for op in operations
            ]
        )
        print(f"   è®°å¿†: {memory_result['total_records']} æ¡è®°å½•")

        # MemorySaver
        saver_result = await simulate_langgraph_memory_saver(
            [{**op, "thread_id": thread_name} for op in operations]
        )
        thread_state = saver_result["thread_states"][thread_name]
        print(f"   çŠ¶æ€: {thread_state['message_count']} æ¡æ¶ˆæ¯")

        all_results[thread_name] = {
            "executed": len(dedup_result["executed"]),
            "skipped": len(dedup_result["skipped"]),
            "memory_records": memory_result["total_records"],
            "messages": thread_state["message_count"],
        }

    # æ±‡æ€»ç»Ÿè®¡
    print("\nğŸ“Š å¤šçº¿ç¨‹æ±‡æ€»:")
    total_executed = sum(r["executed"] for r in all_results.values())
    total_skipped = sum(r["skipped"] for r in all_results.values())
    total_operations = sum(len(ops) for ops in test_threads.values())

    print(f"   æ€»æ“ä½œæ•°: {total_operations}")
    print(f"   æ€»æ‰§è¡Œæ•°: {total_executed}")
    print(f"   æ€»è·³è¿‡æ•°: {total_skipped}")
    print(f"   å…¨å±€æ•ˆç‡: {((total_skipped / total_operations) * 100):.1f}%")

    return all_results


async def test_error_recovery_scenario():
    """æµ‹è¯•é”™è¯¯æ¢å¤åœºæ™¯"""
    print("\n" + "=" * 70)
    print("æµ‹è¯•åœºæ™¯: é”™è¯¯æ¢å¤å’ŒçŠ¶æ€ä¿æŒ")
    print("=" * 70)

    # æ¨¡æ‹ŸåŒ…å«é”™è¯¯çš„æ“ä½œåºåˆ—
    operations_with_errors = [
        {"action": "navigate", "params": {"url": "https://example.com"}},
        {
            "action": "click",
            "params": {"element": "æ­£å¸¸æŒ‰é’®"},
            "result": {"success": True},
        },
        {
            "action": "click",
            "params": {"element": "é”™è¯¯æŒ‰é’®"},
            "result": {"success": False, "error": "å…ƒç´ æœªæ‰¾åˆ°"},
        },
        {
            "action": "click",
            "params": {"element": "é”™è¯¯æŒ‰é’®"},
            "result": {"success": False, "error": "å…ƒç´ æœªæ‰¾åˆ°"},
        },  # é‡å¤é”™è¯¯
        {
            "action": "find_element",
            "params": {"description": "æ›¿ä»£æŒ‰é’®"},
            "result": {"success": True},
        },
        {
            "action": "click",
            "params": {"element": "æ›¿ä»£æŒ‰é’®"},
            "result": {"success": True},
        },
    ]

    print(f"\nâš ï¸  åŒ…å«é”™è¯¯çš„æ“ä½œåºåˆ—:")
    for i, op in enumerate(operations_with_errors, 1):
        result = op.get("result", {"success": True})
        status = "âœ…" if result.get("success", True) else "âŒ"
        print(f"  {i}. {status} {op['action']} {op['params']}")

    # æµ‹è¯•å»é‡ï¼ˆåº”è¯¥è·³è¿‡é‡å¤çš„é”™è¯¯æ“ä½œï¼‰
    print("\nğŸ›¡ï¸  é”™è¯¯å¤„ç†å’Œå»é‡:")
    dedup_result = await simulate_nodejs_deduplication(operations_with_errors)
    print(f"   æ‰§è¡Œæ“ä½œ: {len(dedup_result['executed'])}")
    print(f"   è·³è¿‡æ“ä½œ: {len(dedup_result['skipped'])}")

    # æµ‹è¯•è®°å¿†ï¼ˆåº”è¯¥è®°å½•æˆåŠŸå’Œå¤±è´¥ï¼‰
    print("\nğŸ’¾ é”™è¯¯è®°å¿†è®°å½•:")
    memory_result = await simulate_python_memory(operations_with_errors)
    successful = memory_result["successful_records"]
    total = memory_result["total_records"]
    print(f"   æˆåŠŸè®°å½•: {successful}/{total}")
    print(f"   æˆåŠŸç‡: {(successful / total * 100):.1f}%")

    # æ˜¾ç¤ºå¤±è´¥è®°å½•
    print("\n   å¤±è´¥è®°å½•è¯¦æƒ…:")
    for record in memory_result["records"]:
        if not record["success"]:
            print(
                f"     âŒ {record['action']}: {record['result'].get('error', 'Unknown error')}"
            )

    return {
        "total_operations": len(operations_with_errors),
        "executed": len(dedup_result["executed"]),
        "skipped": len(dedup_result["skipped"]),
        "success_rate": (successful / total * 100),
        "error_handling": True,
    }


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹ç»¼åˆæµ‹è¯•ï¼šé˜¶æ®µ1 + é˜¶æ®µ2 å®Œæ•´é›†æˆ")
    print("æµ‹è¯•æ—¶é—´:", time.strftime("%Y-%m-%d %H:%M:%S"))
    print()

    try:
        # è¿è¡Œæµ‹è¯•åœºæ™¯
        results = {}

        # åœºæ™¯1: basic_usage.txt é‡å¤æ‰§è¡Œé—®é¢˜
        results["basic_usage"] = await test_basic_usage_scenario()

        # åœºæ™¯2: å¤šçº¿ç¨‹å¹¶å‘
        results["multi_thread"] = await test_multiple_threads_scenario()

        # åœºæ™¯3: é”™è¯¯æ¢å¤
        results["error_recovery"] = await test_error_recovery_scenario()

        # æ€»ç»“
        print("\n" + "=" * 70)
        print("ğŸ‰ ç»¼åˆæµ‹è¯•å®Œæˆï¼")
        print("=" * 70)

        print("\nğŸ“‹ æµ‹è¯•ç»“æœæ€»ç»“:")
        for scenario, result in results.items():
            print(f"\nğŸ” {scenario}:")
            if scenario == "basic_usage":
                print(f"   æ•ˆç‡æå‡: {result['efficiency_improvement']:.1f}%")
                print(f"   çŠ¶æ€æŒä¹…åŒ–: {result['message_persistence']} æ¡æ¶ˆæ¯")
                print(f"   å†å²è®°å½•: {result['memory_records']} æ¡")
            elif scenario == "multi_thread":
                print(f"   çº¿ç¨‹æ•°: {len(result)}")
                total_skipped = sum(r["skipped"] for r in result.values())
                print(f"   å…¨å±€è·³è¿‡: {total_skipped} ä¸ªé‡å¤æ“ä½œ")
            elif scenario == "error_recovery":
                print(f"   æˆåŠŸç‡: {result['success_rate']:.1f}%")
                print(f"   é”™è¯¯å¤„ç†: {'âœ…' if result['error_handling'] else 'âŒ'}")

        # æ•´ä½“è¯„ä¼°
        print("\nğŸ“Š æ•´ä½“è¯„ä¼°:")
        basic_improvement = results["basic_usage"]["efficiency_improvement"]
        if basic_improvement > 30:
            print(f"   âœ… é‡å¤æ‰§è¡Œé—®é¢˜æ˜¾è‘—æ”¹å–„ ({basic_improvement:.1f}% æ•ˆç‡æå‡)")
        else:
            print(f"   âš ï¸  é‡å¤æ‰§è¡Œé—®é¢˜æ”¹å–„æœ‰é™ ({basic_improvement:.1f}% æ•ˆç‡æå‡)")

        print(f"   âœ… å¤šçº¿ç¨‹æ”¯æŒ: {len(results['multi_thread'])} ä¸ªå¹¶å‘çº¿ç¨‹")
        print(
            f"   âœ… é”™è¯¯æ¢å¤: {results['error_recovery']['success_rate']:.1f}% æˆåŠŸç‡"
        )

        print("\nğŸ’¡ é˜¶æ®µ1 + é˜¶æ®µ2 å®æ–½çŠ¶æ€:")
        print("âœ… Node.js å»é‡ä¸­é—´ä»¶ - å·¥ä½œæ­£å¸¸")
        print("âœ… Python è®°å¿†ç»„ä»¶ - å·¥ä½œæ­£å¸¸")
        print("âœ… LangGraph MemorySaver - å·¥ä½œæ­£å¸¸")
        print("âœ… ä¸‰è€…ååŒå·¥ä½œ - éªŒè¯é€šè¿‡")

        print("\nğŸš€ ä¸‹ä¸€æ­¥å»ºè®®:")
        print("- é˜¶æ®µ3: ç»Ÿä¸€çŠ¶æ€ç®¡ç†æ¶æ„ (å¯é€‰)")
        print("- ç«¯åˆ°ç«¯æµ‹è¯•: åœ¨çœŸå®ç¯å¢ƒä¸­éªŒè¯æ”¹è¿›æ•ˆæœ")
        print("- æ€§èƒ½åŸºå‡†æµ‹è¯•: å¯¹æ¯”æ”¹è¿›å‰åçš„æ‰§è¡Œæ—¶é—´")

        return 0

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(asyncio.run(main()))
