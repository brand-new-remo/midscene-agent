"""
LangGraph CLI é€‚é…å±‚

è¿™ä¸ªæ¨¡å—å°†ç°æœ‰çš„ MidsceneAgent é€‚é…ä¸º LangGraph CLI å…¼å®¹çš„æ ¼å¼ï¼Œ
æ”¯æŒé€šè¿‡ Agent Chat UI è¿›è¡Œè‡ªç„¶è¯­è¨€å¯¹è¯ã€‚

ä½¿ç”¨æ–¹æ³•:
    langgraph dev
    # è®¿é—® http://localhost:2024 ä½¿ç”¨ Agent Chat UI
"""

from langgraph.graph import StateGraph, MessagesState, START, END
from langchain_core.messages import HumanMessage, AIMessage
from agent.cli_adapter import MidsceneAgentAdapter

logger = __import__("logging").getLogger(__name__)


def create_midscene_graph():
    """
    åˆ›å»º LangGraph CLI å…¼å®¹çš„ç¼–è¯‘å›¾

    è¿”å›:
        CompiledStateGraph: å¯æ‰§è¡Œçš„ LangGraph å›¾
    """
    logger.info("ğŸ”§ åˆ›å»º Midscene LangGraph å›¾...")

    # åˆ›å»ºé€‚é…å™¨
    adapter = MidsceneAgentAdapter()

    # æ„å»ºçŠ¶æ€å›¾
    workflow = StateGraph(MessagesState)

    # æ·»åŠ èŠ‚ç‚¹ï¼šåˆ›å»ºç¬¦åˆ LangGraph è§„èŒƒçš„èŠ‚ç‚¹å‡½æ•°
    async def midscene_node(state: MessagesState) -> MessagesState:
        """
        LangGraph èŠ‚ç‚¹å‡½æ•°ï¼šå¤„ç† Midscene ä»»åŠ¡

        Args:
            state: LangGraph æ¶ˆæ¯çŠ¶æ€

        Returns:
            æ›´æ–°åçš„æ¶ˆæ¯çŠ¶æ€
        """
        # è·å–æœ€æ–°ç”¨æˆ·æ¶ˆæ¯
        if not state.get("messages"):
            return {
                "messages": [AIMessage(content="âŒ æœªæ”¶åˆ°ç”¨æˆ·æ¶ˆæ¯")]
            }

        user_message = state["messages"][-1]
        if not isinstance(user_message, HumanMessage):
            return {
                "messages": state["messages"] + [AIMessage(content="âŒ åªæ”¯æŒ HumanMessage")]
            }

        user_input = str(user_message.content)
        logger.info(f"ğŸ“ æ”¶åˆ°ç”¨æˆ·è¾“å…¥: {user_input[:100]}...")

        # åˆ›å»º Midscene ä¼šè¯
        session_id = await adapter._create_session()
        adapter.active_sessions.add(session_id)

        try:
            # åˆå§‹åŒ– MidsceneAgentï¼ˆå¦‚æœå°šæœªåˆå§‹åŒ–ï¼‰
            if not adapter.agent.initialized:
                await adapter.agent.initialize()
                logger.info("âœ… MidsceneAgent åˆå§‹åŒ–å®Œæˆ")

            # æ‰§è¡Œç”¨æˆ·è¾“å…¥å¹¶æ”¶é›†ç»“æœ
            all_outputs = []
            async for chunk in adapter._execute(user_input, session_id):
                if isinstance(chunk, dict):
                    if "error" in chunk:
                        all_outputs.append(f"âŒ {chunk.get('error')}")
                    else:
                        all_outputs.append(str(chunk))
                else:
                    all_outputs.append(str(chunk))

            # è¿”å›åŒ…å« AI å“åº”çš„çŠ¶æ€
            response_message = "\n".join(all_outputs) if all_outputs else "æ‰§è¡Œå®Œæˆ"
            return {
                "messages": state["messages"] + [AIMessage(content=response_message)]
            }

        except Exception as e:
            error_msg = f"âŒ æ‰§è¡Œå¤±è´¥: {str(e)}"
            logger.error(f"{error_msg}\n{__import__('traceback').format_exc()}")
            return {
                "messages": state["messages"] + [AIMessage(content=error_msg)]
            }

        finally:
            # æ¸…ç†ä¼šè¯
            try:
                await adapter._cleanup_session(session_id)
            except Exception as e:
                logger.error(f"æ¸…ç†ä¼šè¯æ—¶å‡ºé”™: {e}")
            finally:
                adapter.active_sessions.discard(session_id)

    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("midscene_agent", midscene_node)

    # è®¾ç½®æµç¨‹ï¼šå…¥å£ -> agent -> ç»“æŸ
    workflow.add_edge(START, "midscene_agent")
    workflow.add_edge("midscene_agent", END)

    # ç¼–è¯‘å›¾
    graph = workflow.compile()

    logger.info("âœ… Midscene LangGraph å›¾åˆ›å»ºå®Œæˆ")
    return graph


# å¯¼å‡º CompiledGraph å˜é‡ï¼ˆLangGraph CLI è¦æ±‚ï¼‰
# å˜é‡åå¿…é¡»æ˜¯ 'graph'
graph = create_midscene_graph()
